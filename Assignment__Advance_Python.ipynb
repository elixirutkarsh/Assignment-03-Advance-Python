{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Create a file that contains 1000 lines of random strings."
      ],
      "metadata": {
        "id": "lyaatYmINNU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2NEX53lM_jO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "def generate_random_string(length):\n",
        "    return ''.join(random.choices(string.ascii_letters, k=length))\n",
        "\n",
        "file_path = 'random_strings_1000.txt'\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    for _ in range(1000):\n",
        "        random_string = generate_random_string(10)  # Adjust the length of the random string as needed\n",
        "        file.write(random_string + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Create a file that contains multiple lines of random strings and file size must be 5 MB."
      ],
      "metadata": {
        "id": "JdUXKRRaNLCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import os\n",
        "\n",
        "def generate_random_string(length):\n",
        "    return ''.join(random.choices(string.ascii_letters, k=length))\n",
        "\n",
        "file_path = 'random_strings_5mb.txt'\n",
        "file_size = 5 * 1024 * 1024  # 5 MB\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    while os.stat(file_path).st_size < file_size:\n",
        "        random_string = generate_random_string(10)  # Adjust the length of the random string as needed\n",
        "        file.write(random_string + '\\n')\n"
      ],
      "metadata": {
        "id": "Be6tjKobNkWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Create 10 files that contains multiple lines of random strings and file size of each file must be 5 MB."
      ],
      "metadata": {
        "id": "viRmnBAfNnFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import os\n",
        "\n",
        "def generate_random_string(length):\n",
        "    return ''.join(random.choices(string.ascii_letters, k=length))\n",
        "\n",
        "folder_path = 'random_strings_folder'\n",
        "file_size = 5 * 1024 * 1024  # 5 MB\n",
        "\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "for i in range(1, 11):\n",
        "    file_path = os.path.join(folder_path, f'random_strings_{i}.txt')\n",
        "    with open(file_path, 'w') as file:\n",
        "        while os.stat(file_path).st_size < file_size:\n",
        "            random_string = generate_random_string(10)  # Adjust the length of the random string as needed\n",
        "            file.write(random_string + '\\n')\n"
      ],
      "metadata": {
        "id": "XrjBUS4JNnou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Create 5 files of size 1GB, 2GB, 3GB, 4GB and 5GB; file contains multiple lines of random strings.\n"
      ],
      "metadata": {
        "id": "-Rb7Iq7sNn9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import os\n",
        "\n",
        "def generate_random_string(length):\n",
        "    return ''.join(random.choices(string.ascii_letters, k=length))\n",
        "\n",
        "folder_path = 'random_strings_folder'\n",
        "\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "file_sizes = [1, 2, 3, 4, 5]  # Sizes in GB\n",
        "\n",
        "for size in file_sizes:\n",
        "    file_size = size * 1024 * 1024 * 1024  # Convert size to bytes\n",
        "    file_path = os.path.join(folder_path, f'random_strings_{size}gb.txt')\n",
        "    with open(file_path, 'w') as file:\n",
        "        while os.stat(file_path).st_size < file_size:\n",
        "            random_string = generate_random_string(10)  # Adjust the length of the random string as needed\n",
        "            file.write(random_string + '\\n')\n"
      ],
      "metadata": {
        "id": "7S_PUqC7NojF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Convert all the files of Q4 into upper case one by one.\n"
      ],
      "metadata": {
        "id": "3byyVHjENpP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "folder_path = 'random_strings_folder'\n",
        "\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith('.txt'):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        with open(file_path, 'r+') as file:\n",
        "            content = file.read().upper()\n",
        "            file.seek(0)\n",
        "            file.write(content)\n",
        "            file.truncate()\n",
        "\n"
      ],
      "metadata": {
        "id": "3nb7jz2ANptJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Convert all the files of Q4 into upper case parallel using multi-threading."
      ],
      "metadata": {
        "id": "OjM3iK69NqSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "folder_path = 'random_strings_folder'\n",
        "\n",
        "def convert_to_upper_case(file_path):\n",
        "    with open(file_path, 'r+') as file:\n",
        "        content = file.read().upper()\n",
        "        file.seek(0)\n",
        "        file.write(content)\n",
        "        file.truncate()\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            executor.submit(convert_to_upper_case, file_path)\n"
      ],
      "metadata": {
        "id": "VmK10b2oNqre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q7. WAP to automatically download 10 images of cat from “Google Images”. [Hint: Find the package from pypi.org and use it]\n"
      ],
      "metadata": {
        "id": "hM83OptVOLns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "# Set the search query and limit\n",
        "search_query = \"cat\"\n",
        "limit = 10\n",
        "\n",
        "# Create an instance of the downloader\n",
        "downloader = google_images_download.googleimagesdownload()\n",
        "\n",
        "# Set the download arguments\n",
        "download_args = {\n",
        "    \"keywords\": search_query,\n",
        "    \"limit\": limit,\n",
        "    \"output_directory\": \"cat_images\"\n",
        "}\n",
        "\n",
        "# Download images\n",
        "response = downloader.download(download_args)\n",
        "\n",
        "# Print the downloaded images\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "VqvOuz-vOMI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q8. WAP to automatically download 10 videos of “Machine Learning” from “Youtube.com”. [Hint: Find the package from pypi.org and use it]\n"
      ],
      "metadata": {
        "id": "4ef2s9e7OMhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "search_query = \"Machine Learning\"\n",
        "limit = 10\n",
        "\n",
        "youtube_url = f\"https://www.youtube.com/results?search_query={search_query}\"\n",
        "videos = YouTube.search(url=youtube_url, limit=limit)\n",
        "\n",
        "for video in videos:\n",
        "    video.streams.get_highest_resolution().download(output_path=\"machine_learning_videos\")\n"
      ],
      "metadata": {
        "id": "MQrEpVDKONEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q9. Convert all the videos of Q8 and convert it to audio. [Hint: Find the package from pypi.org and use it]"
      ],
      "metadata": {
        "id": "aFxbUlZwONhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "videos_folder = \"machine_learning_videos\"\n",
        "audio_folder = \"machine_learning_audios\"\n",
        "\n",
        "os.makedirs(audio_folder, exist_ok=True)\n",
        "\n",
        "for video_file in os.listdir(videos_folder):\n",
        "    if video_file.endswith('.mp4'):\n",
        "        video_path = os.path.join(videos_folder, video_file)\n",
        "        audio_file = os.path.splitext(video_file)[0] + \".mp3\"\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        audio_clip = video_clip.audio\n",
        "        audio_clip.write_audiofile(audio_path)\n",
        "        video_clip.close()\n"
      ],
      "metadata": {
        "id": "itzZeEyiON9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q10. Create an automated pipeline using multi-threading for:\n",
        "“Automatic Download of 100 Videos from YouTube” → “Convert it to Audio”.\n"
      ],
      "metadata": {
        "id": "k3A5Nqi5OOUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "search_query = \"Machine Learning\"\n",
        "limit = 100\n",
        "\n",
        "youtube_url = f\"https://www.youtube.com/results?search_query={search_query}\"\n",
        "videos_folder = \"machine_learning_videos\"\n",
        "audio_folder = \"machine_learning_audios\"\n",
        "\n",
        "os.makedirs(videos_folder, exist_ok=True)\n",
        "os.makedirs(audio_folder, exist_ok=True)\n",
        "\n",
        "lock = threading.Lock()\n",
        "counter = 0\n",
        "\n",
        "def download_video(video_url):\n",
        "    global counter\n",
        "    video = YouTube(video_url)\n",
        "    video.streams.get_highest_resolution().download(output_path=videos_folder)\n",
        "    lock.acquire()\n",
        "    counter += 1\n",
        "    print(f\"Downloaded video {counter}/{limit}\")\n",
        "    lock.release()\n",
        "\n",
        "def convert_to_audio(video_file):\n",
        "    video_path = os.path.join(videos_folder, video_file)\n",
        "    audio_file = os.path.splitext(video_file)[0] + \".mp3\"\n",
        "    audio_path = os.path.join(audio_folder, audio_file)\n",
        "    video_clip = VideoFileClip(video_path)\n",
        "    audio_clip = video_clip.audio\n",
        "    audio_clip.write_audiofile(audio_path)\n",
        "    video_clip.close()\n",
        "    lock.acquire()\n",
        "    counter += 1\n",
        "    print(f\"Converted video {counter}/{limit} to audio\")\n",
        "    lock.release()\n",
        "\n",
        "threads = []\n",
        "\n",
        "# Download videos\n",
        "for video in YouTube.search(url=youtube_url, limit=limit):\n",
        "    video_url = f\"https://www.youtube.com/watch?v={video.video_id}\"\n",
        "    thread = threading.Thread(target=download_video, args=(video_url,))\n",
        "    threads.append(thread)\n",
        "    thread.start()\n",
        "\n",
        "# Wait for all download threads to finish\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "# Reset counter for audio conversion\n",
        "counter = 0\n",
        "\n",
        "# Convert videos to audio\n",
        "for video_file in os.listdir(videos_folder):\n",
        "    if video_file.endswith('.mp4'):\n",
        "        thread = threading.Thread(target=convert_to_audio, args=(video_file,))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "# Wait for all conversion threads to finish\n",
        "for thread in threads:\n",
        "    thread.join()\n"
      ],
      "metadata": {
        "id": "_v_2bgozOO1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q11. Create an automated pipeline using multi-threading for: “Automatic Download of 500 images of Dog from GoogleImages” → “Rescale it to 50%”."
      ],
      "metadata": {
        "id": "VCIr53nWOQat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "from google_images_download import google_images_download\n",
        "from PIL import Image\n",
        "\n",
        "search_query = \"dog\"\n",
        "limit = 500\n",
        "rescale_factor = 0.5\n",
        "\n",
        "image_folder = \"dog_images\"\n",
        "rescaled_folder = \"rescaled_dog_images\"\n",
        "\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "os.makedirs(rescaled_folder, exist_ok=True)\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "\n",
        "arguments = {\n",
        "    \"keywords\": search_query,\n",
        "    \"limit\": limit,\n",
        "    \"print_urls\": True,\n",
        "    \"output_directory\": image_folder\n",
        "}\n",
        "\n",
        "response.download(arguments)\n",
        "\n",
        "lock = threading.Lock()\n",
        "counter = 0\n",
        "\n",
        "def rescale_image(image_file):\n",
        "    global counter\n",
        "    image_path = os.path.join(image_folder, image_file)\n",
        "    rescaled_file = f\"rescaled_{image_file}\"\n",
        "    rescaled_path = os.path.join(rescaled_folder, rescaled_file)\n",
        "    image = Image.open(image_path)\n",
        "    rescaled_image = image.resize((int(image.width * rescale_factor), int(image.height * rescale_factor)))\n",
        "    rescaled_image.save(rescaled_path)\n",
        "    lock.acquire()\n",
        "    counter += 1\n",
        "    print(f\"Rescaled image {counter}/{limit}\")\n",
        "    lock.release()\n",
        "\n",
        "threads = []\n",
        "\n",
        "# Rescale images\n",
        "for image_file in os.listdir(image_folder):\n",
        "    thread = threading.Thread(target=rescale_image, args=(image_file,))\n",
        "    threads.append(thread)\n",
        "    thread.start()\n",
        "\n",
        "# Wait for all rescaling threads to finish\n",
        "for thread in threads:\n",
        "    thread.join()\n"
      ],
      "metadata": {
        "id": "ixcEwJwHSdHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "p07Ss2o6OPT2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPkceX7IScCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXdt_L3DOQFG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}